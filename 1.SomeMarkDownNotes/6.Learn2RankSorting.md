---
##综述
learning2rank方法的叙述：http://blog.csdn.net/hguisu/article/details/7989489，
数据格式：
数据格式和libsvm所用格式类似，参考 https://www.microsoft.com/en-us/research/project/mslr/ 
了解数据的准备工作。评判指标采用DCG,NDCG,MAP等，其中NDCG使用更多。

---
##pointwise的实现：
就是最常见的回归问题。

---
##pairwise的实现：
[RankingSVM实现](https://github.com/rth/pysofia/)对输入数据的格式与上面有点不同，而且就是转化为SVM分类来实现pair对排序的。
除了Ranking SVM方法之外，Pairwise的方法还有RankNet, LambdaRank等。
http://www.cs.cornell.edu/People/tj/svm_light/svm_rank.html
https://sourceforge.net/p/lemur/wiki/RankLib%20File%20Format/

[Learning2rank在淘宝的应用](http://club.alibabatech.org/article_detail.htm?articleId=54) 
这篇博文主要讨论了如何通过用户的点击与购买反馈来生产表示商品好坏的pair对（当然使用人工标注的方法也可以，但是太耗时耗力了）。
另外为了使排序的参数变化不至于太剧烈，形成一些意想不到的badcase。
在样本中加入一部分通过原始排序来生成的pair（无点击的数据），将所有的pair混合在一起训练模型，并调整混合比例多次训练。

---
##listwise的实现：
LambdaMART是一种Listwise类型的LTR算法，它基于LambdaRank算法和MART算法，将搜索引擎结果排序问题转化为回归决策树问题。
简单的讲就是Ranking常见的评价指标(NDCG等)都无法求梯度，因此没法直接对评价指标(比如NDCG)做梯度下降。
RankNet的创新之处在于将不适宜用梯度下降求解的Ranking问题，转化为对偏序概率的交叉熵损失函数的优化问题，从而适用梯度下降方法，
它告诉我们如何绕开NDCG等无法求导的评价指标得到一个可用的梯度。
然后我们绕开损失函数，直接定义梯度，并考虑引入评价指标ZZ(比如NDCG)的变化，这样就得到了需要的lambda表达式(就相当于得到了要优化的目标函数)，然后用MART去拟合这个值。
具体见博文[LambdaMART不太简短之介绍](http://liam0205.me/2016/07/10/a-not-so-simple-introduction-to-lambdamart/)。 
完整的代码实现见https://sourceforge.net/p/lemur/wiki/RankLib/开源库，还实现了其余的一些算法。
另外[LambdaMART实现] https://github.com/jma127/pyltr 是lambdamart的简易版本的实现。 

这两篇博文分析源码也可以看看其操作流程。
[LambdaMART简介——基于Ranklib源码 (一 lambda计算)](http://www.cnblogs.com/wowarsenal/p/3900359.html)
[LambdaMART简介——基于Ranklib源码 (二 RegressionTree训练)](http://www.cnblogs.com/wowarsenal/p/3906081.html)